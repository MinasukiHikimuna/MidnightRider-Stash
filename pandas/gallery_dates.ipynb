{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dotenv\n",
    "import os\n",
    "from libraries.client_stashapp import get_stashapp_client\n",
    "from libraries.StashDbClient import StashDbClient\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "stash = get_stashapp_client()\n",
    "\n",
    "stashbox_client = StashDbClient(\n",
    "    os.getenv(\"STASHDB_ENDPOINT\"),\n",
    "    os.getenv(\"STASHDB_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galleries = stash.find_galleries(fragment=\"id title files { basename } studio { id name }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_galleries = pd.DataFrame(galleries)\n",
    "\n",
    "# Filter galleries with a single file\n",
    "df_single_file_galleries = df_galleries[df_galleries['files'].apply(lambda x: len(x) == 1)].copy()\n",
    "\n",
    "# Extract basename of the single file\n",
    "df_single_file_galleries.loc[:, 'file_basename'] = df_single_file_galleries['files'].apply(lambda x: os.path.basename(x[0]['basename']))\n",
    "\n",
    "# Reset index for cleaner output\n",
    "df_single_file_galleries = df_single_file_galleries.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse date from file_basename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the specified columns\n",
    "df_single_file_galleries_dates = df_single_file_galleries[['id', 'date', 'title', 'file_basename']]\n",
    "\n",
    "# Parse date from file_basename and create a new column\n",
    "df_single_file_galleries_dates['parsed_date'] = df_single_file_galleries_dates['file_basename'].str.extract(r'(\\d{4}-\\d{2}-\\d{2})')[0]\n",
    "\n",
    "df_single_file_galleries_dates = df_single_file_galleries_dates[(df_single_file_galleries_dates['date'].isna()) & ((df_single_file_galleries_dates['parsed_date'].notna()) & (df_single_file_galleries_dates['parsed_date'] != \"0001-01-01\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_single_file_galleries.iterrows():\n",
    "    stash.update_gallery({\n",
    "        \"id\": row[\"id\"],\n",
    "        \"date\": row[\"parsed_date\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse studio from file_basename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the specified columns and create a copy\n",
    "df_single_file_galleries_studios = df_single_file_galleries[['id', 'studio', 'title', 'file_basename']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_studio = \"WowPorn\"\n",
    "\n",
    "def clean_data(df_single_file_galleries_studios):\n",
    "    # Derive column 'gallery_date' from column: 'file_basename'\n",
    "    # Transform based on the following examples:\n",
    "    #    file_basename                                             Output\n",
    "    # 1: \"MetArt - 2010-02-08 - 20100208WHY_METART_______ - Why => \"2010-02-08\"\n",
    "    #    Metart... -) - Ariel Piper Fawn [high].zip\"\n",
    "    df_single_file_galleries_studios.insert(4, \"gallery_date\", df_single_file_galleries_studios[\"file_basename\"].str.split(\" \").str[2])\n",
    "\n",
    "    # Derive column 'gallery_studio' from column: 'file_basename'\n",
    "    # Transform based on the following examples:\n",
    "    #    file_basename                                                 Output\n",
    "    # 1: \"MetArt - 2008-09-22 - 20080922STEAMING - Steaming - Ariel => \"MetArt\"\n",
    "    #    Piper Fawn [high].zip\"\n",
    "    df_single_file_galleries_studios.insert(4, \"gallery_studio\", df_single_file_galleries_studios[\"file_basename\"].str.split(\"-\").str[0].str.strip())\n",
    "\n",
    "    # Derive column 'gallery_title' from column: 'file_basename'\n",
    "    # Transform based on the following examples:\n",
    "    #    file_basename                                                Output\n",
    "    # 1: \"MetArt - 2022-05-25 - 20220525PRESENTING_KELLY_COLLINS - => \"Presenting Kelly Collins\"\n",
    "    #    Presenting Kelly Collins - Kelly Collins [high].zip\"\n",
    "    df_single_file_galleries_studios.insert(4, \"gallery_title\", df_single_file_galleries_studios[\"file_basename\"].str.split(\"-\").str[5].str.strip())\n",
    "\n",
    "    # Filter rows based on columns: 'gallery_date', 'gallery_title', 'gallery_studio'\n",
    "    df_single_file_galleries_studios = df_single_file_galleries_studios[(df_single_file_galleries_studios['gallery_date'].notna()) & (df_single_file_galleries_studios['gallery_title'].notna()) & (df_single_file_galleries_studios['gallery_studio'].notna())]\n",
    "\n",
    "    # Filter rows based on column: 'gallery_studio'\n",
    "    df_single_file_galleries_studios = df_single_file_galleries_studios[df_single_file_galleries_studios['gallery_studio'] == selected_studio]\n",
    "\n",
    "    # Derive column 'gallery_performers' from column: 'file_basename'\n",
    "    # Transform based on the following examples:\n",
    "    #    file_basename                                                Output\n",
    "    # 1: \"MetArt - 2022-02-24 - 20220224GRATIFY - Gratify - Stella => \"Stella Cardo\"\n",
    "    #    Cardo [high].zip\"\n",
    "    # 2: \"MetArt - 2011-11-27 - 20111127PRESENTING_MICHELLE -      => \"Michelle H\"\n",
    "    #    Presenting Michelle - Michelle H [high].zip\"\n",
    "    # 3: \"MetArt - 2010-02-08 - 20100208WHY_METART_______ - Why    => \"Ariel Piper Fawn\"\n",
    "    #    Metart... -) - Ariel Piper Fawn [high].zip\"\n",
    "    df_single_file_galleries_studios.insert(4, \"gallery_performers\", df_single_file_galleries_studios.apply(lambda row : row[\"file_basename\"][row[\"file_basename\"].rfind(\"-\") + 2:row[\"file_basename\"].rfind(\" \")], axis=1))\n",
    "    \n",
    "    # Derive column 'gallery_performers_separated' from column: 'gallery_performers'\n",
    "    def gallery_performers_separated(gallery_performers):\n",
    "        import re\n",
    "\n",
    "        \"\"\"\n",
    "        Transform based on the following examples:\n",
    "           gallery_performers                Output\n",
    "        1: \"Ariel Piper Fawn\"             => \"Ariel Piper Fawn\"\n",
    "        2: \"Melisa A & Caprice A\"         => \"Melisa A, Caprice A\"\n",
    "        3: \"Michelle H\"                   => \"Michelle H\"\n",
    "        4: \"Vera\"                         => \"Vera\"\n",
    "        5: \"Vera & Michelle H\"            => \"Vera, Michelle H\"\n",
    "        6: \"Vera, Michelle H & Ariel Piper Fawn\" => \"Vera, Michelle H, Ariel Piper Fawn\"\n",
    "        \"\"\"\n",
    "        # Split by '&' and ',' to handle both separators\n",
    "        performers = [p.strip() for p in re.split('[&,]', gallery_performers)]\n",
    "        \n",
    "        # Remove any empty strings that might result from splitting\n",
    "        performers = [p for p in performers if p]\n",
    "        \n",
    "        # Join the performers with a comma and space\n",
    "        return ', '.join(performers)\n",
    "\n",
    "    df_single_file_galleries_studios.insert(5, \"gallery_performers_separated\", df_single_file_galleries_studios.apply(lambda row : gallery_performers_separated(row[\"gallery_performers\"]), axis=1))\n",
    "\n",
    "    df_single_file_galleries_studios.insert(4, \"gallery_studio_code\", df_single_file_galleries_studios[\"file_basename\"].str.split(\"-\").str[4].str.strip())\n",
    "\n",
    "    return df_single_file_galleries_studios\n",
    "\n",
    "df_single_file_galleries_studios_clean = clean_data(df_single_file_galleries_studios.copy())\n",
    "df_single_file_galleries_studios_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There might be multiple performers in gallery_performers_separated, so we need to split them into a list and create a new data frame of just the performers so we can match those to Stash performers in df_performers\n",
    "df_performers_list = df_single_file_galleries_studios_clean['gallery_performers_separated'].str.split(',').explode().str.strip().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studios = stash.find_studios(fragment=\"id name\")\n",
    "df_studios = pd.DataFrame(studios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performers = stash.find_performers(fragment=\"id name alias_list\")\n",
    "df_performers = pd.DataFrame(performers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all performers from df_performers_list\n",
    "df_performers_with_stash_ids = pd.DataFrame({'name': df_performers_list})\n",
    "\n",
    "# Function to check if a name matches any alias in the alias_list\n",
    "def match_alias(name, row):\n",
    "    if pd.isna(row['alias_list']).all():\n",
    "        return False\n",
    "    return any(name.lower() == alias.lower() for alias in row['alias_list'] if pd.notna(alias) and alias is not None)\n",
    "\n",
    "# Merge with df_performers to get stash_ids where available, first by name\n",
    "df_performers_with_stash_ids = df_performers_with_stash_ids.merge(\n",
    "    df_performers[['id', 'name', 'alias_list']], \n",
    "    on='name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# For unmatched performers, try matching by alias\n",
    "for idx, row in df_performers_with_stash_ids[df_performers_with_stash_ids['id'].isna()].iterrows():\n",
    "    match = df_performers[df_performers.apply(lambda x: match_alias(row['name'], x), axis=1)]\n",
    "    if not match.empty:\n",
    "        df_performers_with_stash_ids.loc[idx, 'id'] = match.iloc[0]['id']\n",
    "\n",
    "# Rename 'id' column to 'stash_id'\n",
    "df_performers_with_stash_ids = df_performers_with_stash_ids.rename(columns={'id': 'stash_id'})\n",
    "\n",
    "# Drop the 'alias_list' column as it's no longer needed\n",
    "df_performers_with_stash_ids = df_performers_with_stash_ids.drop(columns=['alias_list'])\n",
    "\n",
    "# Sort the DataFrame by name for better readability\n",
    "df_performers_with_stash_ids = df_performers_with_stash_ids.sort_values('name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match performers in df_performers_with_stash_ids to df_single_file_galleries_studios_clean and create a new column with the stash_ids\n",
    "def get_performer_ids(performers):\n",
    "    performer_list = performers.split(',')\n",
    "    ids = []\n",
    "    for performer in performer_list:\n",
    "        performer = performer.strip()\n",
    "        matched_ids = df_performers_with_stash_ids[\n",
    "            (df_performers_with_stash_ids['name'].str.contains(performer, case=False, na=False)) &\n",
    "            (df_performers_with_stash_ids['stash_id'].notna())\n",
    "        ]['stash_id'].tolist()\n",
    "        ids.extend(matched_ids)\n",
    "    return ids if ids else None\n",
    "\n",
    "df_single_file_galleries_studios_clean['stash_ids'] = df_single_file_galleries_studios_clean['gallery_performers_separated'].apply(get_performer_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_studio_id(studio_name):\n",
    "    matched_ids = df_studios[\n",
    "        (df_studios['name'].str.contains(studio_name, case=False, na=False)) &\n",
    "        (df_studios['id'].notna())\n",
    "    ]['id'].tolist()\n",
    "    return matched_ids[0] if matched_ids else None\n",
    "\n",
    "df_single_file_galleries_studios_clean['studio_id'] = df_single_file_galleries_studios_clean['gallery_studio'].apply(get_studio_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually override the studio ID\n",
    "df_single_file_galleries_studios_clean['studio_id'] = '103'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gallery = df_single_file_galleries_studios_clean.iloc[0]\n",
    "print(first_gallery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stash.update_gallery({\n",
    "    \"id\": first_gallery[\"id\"],\n",
    "    \"title\": first_gallery[\"gallery_title\"],\n",
    "    \"date\": first_gallery[\"gallery_date\"],\n",
    "    \"studio_id\": first_gallery[\"studio_id\"],\n",
    "    \"performer_ids\": first_gallery[\"stash_ids\"],\n",
    "    \"code\": first_gallery[\"gallery_studio_code\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_single_file_galleries_studios_clean.iterrows():\n",
    "    stash.update_gallery({\n",
    "        \"id\": row[\"id\"],\n",
    "        \"title\": row[\"gallery_title\"],\n",
    "        \"date\": row[\"gallery_date\"],\n",
    "        \"studio_id\": row[\"studio_id\"],\n",
    "        \"performer_ids\": row[\"stash_ids\"],\n",
    "        \"code\": row[\"gallery_studio_code\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching galleries and scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galleries = stash.find_galleries({ \"studios\": { \"value\": [\"103\"], \"modifier\": \"INCLUDES_ALL\" } })\n",
    "df_galleries_for_matching = pd.DataFrame(galleries)\n",
    "df_galleries_for_matching['gallery_id'] = df_galleries_for_matching['id']\n",
    "df_galleries_for_matching['gallery_date'] = df_galleries_for_matching['date']\n",
    "df_galleries_for_matching[\"gallery_title\"] = df_galleries_for_matching[\"title\"]\n",
    "df_galleries_for_matching = df_galleries_for_matching[['gallery_id', 'gallery_date', 'gallery_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = stash.find_scenes({ \"studios\": { \"value\": [\"103\"], \"modifier\": \"INCLUDES_ALL\" } })\n",
    "df_scenes_for_matching = pd.DataFrame(scenes)\n",
    "df_scenes_for_matching['scene_id'] = df_scenes_for_matching['id']\n",
    "df_scenes_for_matching['scene_date'] = df_scenes_for_matching['date']\n",
    "df_scenes_for_matching[\"scene_title\"] = df_scenes_for_matching[\"title\"]\n",
    "df_scenes_for_matching = df_scenes_for_matching[['scene_id', 'scene_date', 'scene_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data frames by gallery_date and scene_date\n",
    "df_merged = pd.merge(df_galleries_for_matching, df_scenes_for_matching, \n",
    "                     left_on='gallery_title', right_on='scene_title', \n",
    "                     how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first row\n",
    "print(df_merged.iloc[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stash.update_gallery({\n",
    "    \"id\": df_merged.iloc[0][\"gallery_id\"],\n",
    "    \"scene_ids\": [df_merged.iloc[0][\"scene_id\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_merged.iterrows():\n",
    "    stash.update_gallery({\n",
    "        \"id\": row[\"gallery_id\"],\n",
    "        \"scene_ids\": [row[\"scene_id\"]]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get metadata from PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install psycopg2-binary\n",
    "%pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the connection string from environment variable\n",
    "connection_string = os.getenv('CONNECTION_STRING')\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Example query\n",
    "query = \"\"\"\n",
    "SELECT d.*, r.url, r.description, r.short_name\n",
    "FROM downloads d\n",
    "JOIN releases r ON d.release_uuid = r.uuid\n",
    "JOIN sites s ON r.site_uuid = s.uuid\n",
    "WHERE s.name = 'MetArt'\n",
    "\"\"\"\n",
    "\n",
    "# Read data from PostgreSQL into a pandas DataFrame\n",
    "df_downloads = pd.read_sql_query(query, engine)\n",
    "\n",
    "# Close the database connection\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_galleries = pd.DataFrame(galleries)\n",
    "\n",
    "# Filter galleries with a single file\n",
    "df_single_file_galleries = df_galleries[df_galleries['files'].apply(lambda x: len(x) == 1)].copy()\n",
    "\n",
    "# Extract basename of the single file\n",
    "df_single_file_galleries.loc[:, 'file_basename'] = df_single_file_galleries['files'].apply(lambda x: os.path.basename(x[0]['basename']))\n",
    "\n",
    "# Reset index for cleaner output\n",
    "df_single_file_galleries = df_single_file_galleries.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_single_file_galleries with df_downloads based on file_basename and saved_filename\n",
    "df_merged = pd.merge(\n",
    "    df_single_file_galleries,\n",
    "    df_downloads,\n",
    "    left_on='file_basename',\n",
    "    right_on='saved_filename',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Check the number of matches\n",
    "print(f\"Number of matched galleries: {len(df_merged)}\")\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "print(df_merged[['file_basename', 'saved_filename', 'created_at']].head())\n",
    "\n",
    "# Check for galleries that didn't match\n",
    "unmatched_galleries = df_single_file_galleries[~df_single_file_galleries['file_basename'].isin(df_downloads['saved_filename'])]\n",
    "print(f\"Number of unmatched galleries: {len(unmatched_galleries)}\")\n",
    "\n",
    "# If there are unmatched galleries, you might want to investigate why\n",
    "if len(unmatched_galleries) > 0:\n",
    "    print(\"Sample of unmatched galleries:\")\n",
    "    print(unmatched_galleries['file_basename'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first gallery\n",
    "first_gallery = df_merged.iloc[0]\n",
    "print(first_gallery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_merged.iterrows():\n",
    "    stash.update_gallery({\n",
    "        \"id\": row[\"id\"],\n",
    "        \"code\": row[\"short_name\"],\n",
    "        \"url\": row[\"url\"],\n",
    "        \"details\": row[\"description\"]\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
